{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHM\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\SHM\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "num_data = 1000\n",
    "num_epoch = 1000\n",
    "noise = init.normal(torch.FloatTensor(num_data, 1), std=1)\n",
    "x = init.uniform(torch.Tensor(num_data, 1), -10, 10)\n",
    "\n",
    "y = 2*x+3\n",
    "y_noise = y+noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(1, 1)\n",
    "output = model(Variable(x))\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(233.3512, grad_fn=<MseLossBackward>)\n",
      "tensor(10.2438, grad_fn=<MseLossBackward>)\n",
      "tensor(7.1768, grad_fn=<MseLossBackward>)\n",
      "tensor(5.1287, grad_fn=<MseLossBackward>)\n",
      "tensor(3.7610, grad_fn=<MseLossBackward>)\n",
      "tensor(2.8478, grad_fn=<MseLossBackward>)\n",
      "tensor(2.2379, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8307, grad_fn=<MseLossBackward>)\n",
      "tensor(1.5588, grad_fn=<MseLossBackward>)\n",
      "tensor(1.3772, grad_fn=<MseLossBackward>)\n",
      "tensor(1.2559, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1749, grad_fn=<MseLossBackward>)\n",
      "tensor(1.1208, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0847, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0606, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0445, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0338, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0266, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0218, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0186, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0165, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0150, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0141, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0134, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0130, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0127, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0125, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0124, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0123, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0123, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n",
      "tensor(1.0122, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss_arr = []\n",
    "label = Variable(y_noise)\n",
    "for i in range(num_epoch):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(Variable(x))\n",
    "    \n",
    "    loss = loss_func(output, label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(loss)\n",
    "#     print(loss.data.numpy())\n",
    "    loss_arr.append(loss.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.9951]]) tensor([3.0281])\n"
     ]
    }
   ],
   "source": [
    "param_list = list(model.parameters())\n",
    "print(param_list[0].data, param_list[1].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader 부르기\n",
    "파이토치는 DataLoader를 불러 model에 넣음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "test_batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to dataset/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████▊| 9887744/9912422 [00:45<00:00, 361085.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST\\raw\\train-images-idx3-ubyte.gz to dataset/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to dataset/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "  0%|                                                                                        | 0/28881 [00:00<?, ?it/s]\n",
      " 57%|█████████████████████████████████████████▍                               | 16384/28881 [00:01<00:00, 59148.18it/s]\n",
      "32768it [00:01, 31999.97it/s]                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST\\raw\\train-labels-idx1-ubyte.gz to dataset/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to dataset/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "  0%|                                                                                      | 0/1648877 [00:00<?, ?it/s]\n",
      "  1%|▋                                                                      | 16384/1648877 [00:01<00:17, 93632.58it/s]\n",
      "  2%|█▋                                                                    | 40960/1648877 [00:01<00:15, 102342.07it/s]\n",
      "  3%|██▍                                                                   | 57344/1648877 [00:01<00:14, 107819.57it/s]\n",
      "  4%|███▏                                                                  | 73728/1648877 [00:01<00:14, 107811.36it/s]\n",
      "  6%|████▍                                                                | 106496/1648877 [00:01<00:12, 126391.02it/s]\n",
      "  8%|█████▍                                                               | 131072/1648877 [00:01<00:11, 129682.35it/s]\n",
      " 10%|██████▊                                                              | 163840/1648877 [00:02<00:10, 136263.43it/s]\n",
      " 12%|████████▌                                                            | 204800/1648877 [00:02<00:09, 158503.43it/s]\n",
      " 16%|███████████▎                                                         | 270336/1648877 [00:02<00:07, 185482.88it/s]\n",
      " 18%|████████████▎                                                        | 294912/1648877 [00:02<00:07, 181576.25it/s]\n",
      " 20%|██████████████                                                       | 335872/1648877 [00:02<00:06, 196634.64it/s]\n",
      " 22%|███████████████                                                      | 360448/1648877 [00:02<00:06, 190676.11it/s]\n",
      " 24%|████████████████▍                                                    | 393216/1648877 [00:03<00:06, 200053.47it/s]\n",
      " 26%|█████████████████▊                                                   | 425984/1648877 [00:03<00:05, 226520.21it/s]\n",
      " 27%|██████████████████▊                                                  | 450560/1648877 [00:03<00:06, 197803.23it/s]\n",
      " 29%|████████████████████▏                                                | 483328/1648877 [00:03<00:05, 224496.95it/s]\n",
      " 31%|█████████████████████▌                                               | 516096/1648877 [00:03<00:04, 231125.92it/s]\n",
      " 33%|██████████████████████▉                                              | 548864/1648877 [00:03<00:05, 196167.87it/s]\n",
      " 35%|███████████████████████▉                                             | 573440/1648877 [00:04<00:09, 117475.72it/s]\n",
      " 37%|█████████████████████████▎                                           | 606208/1648877 [00:04<00:07, 140244.02it/s]\n",
      " 38%|██████████████████████████▍                                          | 630784/1648877 [00:04<00:08, 121925.98it/s]\n",
      " 40%|███████████████████████████▍                                         | 655360/1648877 [00:04<00:07, 132059.37it/s]\n",
      " 41%|████████████████████████████▍                                        | 679936/1648877 [00:05<00:09, 102885.42it/s]\n",
      " 42%|█████████████████████████████▏                                       | 696320/1648877 [00:05<00:08, 108232.43it/s]\n",
      " 43%|██████████████████████████████▎                                       | 712704/1648877 [00:05<00:11, 81182.53it/s]\n",
      " 44%|██████████████████████████████▉                                       | 729088/1648877 [00:05<00:10, 87113.04it/s]\n",
      " 45%|███████████████████████████████▋                                      | 745472/1648877 [00:06<00:19, 46328.22it/s]\n",
      " 46%|███████████████████████████████▉                                      | 753664/1648877 [00:06<00:18, 49060.76it/s]\n",
      " 46%|████████████████████████████████▎                                     | 761856/1648877 [00:06<00:22, 39255.80it/s]\n",
      " 47%|████████████████████████████████▋                                     | 770048/1648877 [00:06<00:19, 43977.55it/s]\n",
      " 48%|█████████████████████████████████▍                                    | 786432/1648877 [00:07<00:17, 49143.14it/s]\n",
      " 49%|██████████████████████████████████                                    | 802816/1648877 [00:07<00:14, 59626.70it/s]\n",
      " 49%|██████████████████████████████████▍                                   | 811008/1648877 [00:07<00:13, 62838.62it/s]\n",
      " 50%|███████████████████████████████████▏                                  | 827392/1648877 [00:07<00:11, 73963.98it/s]\n",
      " 51%|███████████████████████████████████▊                                  | 843776/1648877 [00:07<00:09, 86983.34it/s]\n",
      " 52%|████████████████████████████████████▌                                 | 860160/1648877 [00:07<00:07, 98846.93it/s]\n",
      " 53%|█████████████████████████████████████▏                                | 876544/1648877 [00:08<00:08, 93467.65it/s]\n",
      " 54%|█████████████████████████████████████▉                                | 892928/1648877 [00:08<00:07, 95551.53it/s]\n",
      " 55%|██████████████████████████████████████▌                               | 909312/1648877 [00:08<00:08, 90107.60it/s]\n",
      " 56%|███████████████████████████████████████▎                              | 925696/1648877 [00:08<00:07, 92991.36it/s]\n",
      " 57%|███████████████████████████████████████▉                              | 942080/1648877 [00:08<00:07, 98566.18it/s]\n",
      " 58%|████████████████████████████████████████▋                             | 958464/1648877 [00:08<00:08, 83525.39it/s]\n",
      " 59%|█████████████████████████████████████████▍                            | 974848/1648877 [00:09<00:07, 90017.68it/s]\n",
      " 60%|██████████████████████████████████████████                            | 991232/1648877 [00:09<00:07, 92613.82it/s]\n",
      " 61%|██████████████████████████████████████████▏                          | 1007616/1648877 [00:09<00:06, 95849.72it/s]\n",
      " 62%|██████████████████████████████████████████▏                         | 1024000/1648877 [00:09<00:05, 105056.24it/s]\n",
      " 63%|██████████████████████████████████████████▉                         | 1040384/1648877 [00:09<00:05, 103255.98it/s]\n",
      " 64%|███████████████████████████████████████████▌                        | 1056768/1648877 [00:09<00:05, 108527.65it/s]\n",
      " 65%|████████████████████████████████████████████▎                       | 1073152/1648877 [00:10<00:05, 107241.55it/s]\n",
      " 66%|████████████████████████████████████████████▉                       | 1089536/1648877 [00:10<00:05, 100674.42it/s]\n",
      " 67%|██████████████████████████████████████████████▎                      | 1105920/1648877 [00:10<00:06, 82590.21it/s]\n",
      " 68%|██████████████████████████████████████████████▉                      | 1122304/1648877 [00:10<00:06, 76288.14it/s]\n",
      " 69%|███████████████████████████████████████████████▋                     | 1138688/1648877 [00:11<00:07, 64242.36it/s]\n",
      " 71%|████████████████████████████████████████████████▋                    | 1163264/1648877 [00:11<00:06, 70947.80it/s]\n",
      " 72%|█████████████████████████████████████████████████▎                   | 1179648/1648877 [00:11<00:07, 66616.60it/s]\n",
      " 73%|██████████████████████████████████████████████████                   | 1196032/1648877 [00:11<00:06, 71965.75it/s]\n",
      " 74%|███████████████████████████████████████████████████                  | 1220608/1648877 [00:12<00:05, 78107.46it/s]\n",
      " 75%|███████████████████████████████████████████████████▊                 | 1236992/1648877 [00:12<00:04, 82943.61it/s]\n",
      "9920512it [01:00, 361085.34it/s]                                                                                       \n",
      " 78%|█████████████████████████████████████████████████████▍               | 1277952/1648877 [00:12<00:04, 91179.50it/s]\n",
      " 78%|██████████████████████████████████████████████████████▏              | 1294336/1648877 [00:12<00:03, 94770.18it/s]\n",
      " 80%|███████████████████████████████████████████████████████▏             | 1318912/1648877 [00:13<00:03, 90510.33it/s]\n",
      " 81%|███████████████████████████████████████████████████████▉             | 1335296/1648877 [00:13<00:03, 86226.28it/s]\n",
      " 82%|████████████████████████████████████████████████████████▉            | 1359872/1648877 [00:13<00:03, 94372.99it/s]\n",
      " 84%|█████████████████████████████████████████████████████████▉           | 1384448/1648877 [00:13<00:02, 95519.17it/s]\n",
      " 85%|██████████████████████████████████████████████████████████▌          | 1400832/1648877 [00:14<00:03, 75095.21it/s]\n",
      " 86%|███████████████████████████████████████████████████████████▋         | 1425408/1648877 [00:14<00:02, 87001.87it/s]\n",
      " 88%|████████████████████████████████████████████████████████████▋        | 1449984/1648877 [00:14<00:02, 90209.32it/s]\n",
      " 89%|█████████████████████████████████████████████████████████████▋       | 1474560/1648877 [00:14<00:01, 95181.04it/s]\n",
      " 91%|█████████████████████████████████████████████████████████████▊      | 1499136/1648877 [00:14<00:01, 100826.49it/s]\n",
      " 92%|███████████████████████████████████████████████████████████████▍     | 1515520/1648877 [00:15<00:01, 89070.30it/s]\n",
      " 93%|████████████████████████████████████████████████████████████████▍    | 1540096/1648877 [00:15<00:01, 91755.13it/s]\n",
      " 95%|█████████████████████████████████████████████████████████████████▍   | 1564672/1648877 [00:15<00:00, 99301.07it/s]\n",
      " 96%|█████████████████████████████████████████████████████████████████▌  | 1589248/1648877 [00:15<00:00, 103765.21it/s]\n",
      " 98%|██████████████████████████████████████████████████████████████████▌ | 1613824/1648877 [00:16<00:00, 104806.18it/s]\n",
      " 99%|███████████████████████████████████████████████████████████████████▌| 1638400/1648877 [00:16<00:00, 111737.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST\\raw\\t10k-images-idx3-ubyte.gz to dataset/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to dataset/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "\n",
      "  0%|                                                                                         | 0/4542 [00:00<?, ?it/s]\n",
      "\n",
      "8192it [00:00, 10394.49it/s]                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to dataset/MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1654784it [00:32, 111737.78it/s]                                                                                       "
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('dataset/', train=True, download=True, \n",
    "                 transform=transforms.Compose([\n",
    "                     transforms.ToTensor(),\n",
    "                     transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "                 ])),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('dataset/', train=False, \n",
    "                  transform = transforms.Compose([\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize((0.5,), (0.5))\n",
    "                  ])),\n",
    "    batch_size = test_batch_size,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫번째 iteration에서 나오는 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 28, 28])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch는 텐서와 다르게 [Batch Size, Channel, Height, Wdith]임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_image = torch.squeeze(images[0])\n",
    "torch_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch_image.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = labels[0].numpy()\n",
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(7, dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17195cadda0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(label)\n",
    "plt.imshow(image,'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
