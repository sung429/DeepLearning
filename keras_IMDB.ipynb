{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_IMDB.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sung429/DeepLearning/blob/master/keras_IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WpC5gOkuYOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZcyvZvmgiFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import imdb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CBlGDBtnzRs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "691d2c49-e365-47b5-8a53-e1683dbfe006"
      },
      "source": [
        "(train_data, train_labels),(test_data, test_labels) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJNXjcDroCR5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b144386d-5037-4b71-aecd-fff762d1a168"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4Kah6fjoJiJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b78783c-f017-498d-aec4-165c8e8a0a8f"
      },
      "source": [
        "test_data.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQL7pj_3oKic",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46516922-e7a9-4f16-aaf1-32f8f7dd642a"
      },
      "source": [
        "type(train_labels)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x40ELsLJoQZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNiCu2AtoRsR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7406c759-e233-453f-c60c-e667bfda8fe8"
      },
      "source": [
        "np.bincount(train_labels)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([12500, 12500])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akvirpIcoT3J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf6f2a6b-fc2a-4e3f-dc53-1cf5507e06cd"
      },
      "source": [
        "max([max(sequence) for sequence in train_data])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwhF6oceogb5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "af646397-431c-4206-ae16-0be0effeafdc"
      },
      "source": [
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = dict(\n",
        "    [(value, key) for (key, value) in word_index.items()]\n",
        ")\n",
        "decoded_review = ' '.join(\n",
        "    [reverse_word_index.get(i - 3, '?') for i in train_data[0]] # 0, 1, 2 는 패딩, 문서 시작, 사전에 없음이므로 3을 뺌\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwW9lxJdp0Lf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d337d893-f1ee-4498-9390-dea089a32a2f"
      },
      "source": [
        "decoded_review"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hy5XXoOtp3Gy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "  results = np.zeros((len(sequences),dimension))\n",
        "  for i, sequence in enumerate(sequences):\n",
        "    results[i, sequence] = 1.\n",
        "  return results\n",
        "\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80ReJOuRsM-_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e9c6c03-5087-4cba-dbe0-6d90c68edf07"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dss_60Fsr-9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3317c6ab-743e-4062-8f46-705f57beb678"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "up-ylrawsteM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fcb59758-a56a-4f87-d39a-ea71cd02ea9a"
      },
      "source": [
        "x_train[0].shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VpgC5Ggsvnb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "378d0f79-3bf0-4511-ecfa-7f53a2fe138a"
      },
      "source": [
        "np.bincount(x_train[0].astype('int64'))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9880,  120])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdwyL5dgszIh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "33de4f81-206c-45e0-d061-a9e5ce467c4b"
      },
      "source": [
        "for i, sequence in enumerate(train_data):\n",
        "  results = np.zeros((25000,10000))\n",
        "  results[i, sequence] = 1.\n",
        "  print(sequence)\n",
        "  break"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-OcK6WEtCSx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "aa06130a-70ad-47ce-a8e5-d520346627dc"
      },
      "source": [
        "results[0, sequence]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wh77Vf7t8XX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "426b9b8a-5c57-43f8-9ffb-febe6ab2cca4"
      },
      "source": [
        "results[0,[1,2]]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnhwaFcKuQQ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e346d8f-2fae-4199-c12f-337250174b21"
      },
      "source": [
        "type(x_train)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhmSB8r0uZk2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3cd32f36-b218-4992-e2d8-ccda1eb7bf26"
      },
      "source": [
        "type(train_labels)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iySLJGYZuH7B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np.asarray(train_labels).astype('float32')\n",
        "y_test = np.asarray(test_labels).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1deDvCAud4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models\n",
        "from keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9H5f9KAyFXO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "1a43c7e1-3045-4b51-fe7f-16679b253c0a"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu',input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdVpqg5Xyl2V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "326b7072-c11a-4ce4-9679-9e852f71bfee"
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6m7Vk06zSGg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_val = x_train[:10000]\n",
        "partial_x_train = x_train[10000:]\n",
        "y_val = y_train[:10000]\n",
        "partial_y_train = y_train[10000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsEg1js8zwHo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b56e8f19-f72c-4e60-c630-2d954a4d8ec3"
      },
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "15000/15000 [==============================] - 5s 361us/step - loss: 0.5069 - acc: 0.7807 - val_loss: 0.3834 - val_acc: 0.8663\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 1s 73us/step - loss: 0.3004 - acc: 0.9017 - val_loss: 0.3031 - val_acc: 0.8877\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 1s 75us/step - loss: 0.2172 - acc: 0.9280 - val_loss: 0.2968 - val_acc: 0.8823\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 1s 73us/step - loss: 0.1735 - acc: 0.9440 - val_loss: 0.2749 - val_acc: 0.8898\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 1s 73us/step - loss: 0.1432 - acc: 0.9537 - val_loss: 0.2881 - val_acc: 0.8881\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 1s 74us/step - loss: 0.1197 - acc: 0.9633 - val_loss: 0.2931 - val_acc: 0.8865\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 1s 73us/step - loss: 0.0954 - acc: 0.9731 - val_loss: 0.3144 - val_acc: 0.8820\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 1s 74us/step - loss: 0.0805 - acc: 0.9766 - val_loss: 0.3308 - val_acc: 0.8818\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 1s 75us/step - loss: 0.0668 - acc: 0.9822 - val_loss: 0.3603 - val_acc: 0.8784\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 1s 74us/step - loss: 0.0558 - acc: 0.9858 - val_loss: 0.4056 - val_acc: 0.8725\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0464 - acc: 0.9888 - val_loss: 0.4186 - val_acc: 0.8734\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0371 - acc: 0.9915 - val_loss: 0.4315 - val_acc: 0.8741\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 1s 72us/step - loss: 0.0299 - acc: 0.9939 - val_loss: 0.4671 - val_acc: 0.8722\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 1s 74us/step - loss: 0.0252 - acc: 0.9948 - val_loss: 0.5028 - val_acc: 0.8692\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 1s 74us/step - loss: 0.0203 - acc: 0.9967 - val_loss: 0.5178 - val_acc: 0.8711\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 1s 72us/step - loss: 0.0149 - acc: 0.9983 - val_loss: 0.5481 - val_acc: 0.8704\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 1s 80us/step - loss: 0.0146 - acc: 0.9974 - val_loss: 0.5810 - val_acc: 0.8690\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 1s 75us/step - loss: 0.0070 - acc: 0.9998 - val_loss: 0.6050 - val_acc: 0.8688\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 1s 73us/step - loss: 0.0069 - acc: 0.9999 - val_loss: 0.6542 - val_acc: 0.8659\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 1s 75us/step - loss: 0.0076 - acc: 0.9989 - val_loss: 0.6821 - val_acc: 0.8662\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaM79pww0OJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_dict = history.history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MV6MtJfh0bzJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "abca023d-ffee-4d60-bd6e-9a81c1dbcb79"
      },
      "source": [
        "history_dict.keys()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6F-Sh0J0dZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWlPmWsD0hXk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "4229fa69-d6f6-43e8-c4f8-7fd113dad6ed"
      },
      "source": [
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZE0p0QgIpLm/j/T1MrxHqz+HQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kL7CXCr1IpV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "6deddedd-18a3-4cdd-8d3b-06e49c4f464e"
      },
      "source": [
        "plt.clf()\n",
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deZwV1Zn/8c/DJqusLSgojYZEGxVo\nW9S4x2jQKIxKVCQ/9xD9iUmcOBNHiDouyWQZf47GcSTGqBFFJg4GM6JRxKBxo1FAwAXE1jQgNqtC\no9Dw/P441XD7Urf7dt+tm/6+X6963apTy31u9e167jlVdcrcHRERkWRtCh2AiIg0T0oQIiISSwlC\nRERiKUGIiEgsJQgREYmlBCEiIrGUICRtZtbWzDaZ2QHZXLaQzOwrZpb1a73N7JtmVpEw/Z6ZHZ/O\nsk14r/vN7Iamri+SSrtCByC5Y2abEiY7A18C26Pp77v7lMZsz923A12zvWxr4O5fy8Z2zOwK4Lvu\nflLCtq/IxrZFkilB7MHcfecBOvqFeoW7P59qeTNr5+41+YhNpCH6PhaemphaMTO7zcweN7PHzOxz\n4LtmdoyZvWZmG8xslZndZWbto+XbmZmbWXE0/Ug0f6aZfW5mr5rZoMYuG80/3czeN7ONZna3mf3N\nzC5JEXc6MX7fzJaZ2Xozuyth3bZm9v/MbK2ZLQdG1rN/JprZ1KSye8zsjmj8CjN7J/o8H0S/7lNt\nq9LMTorGO5vZH6LYFgNHJC07ycyWR9tdbGajovLDgN8Ax0fNd2sS9u3NCetfGX32tWb2pJntm86+\nacx+ro3HzJ43s3Vm9omZ/XPC+/w02iefmVm5me0X15xnZi/X/p2j/Tknep91wCQzG2xms6P3WBPt\nt+4J6w+MPmNVNP8/zKxjFPMhCcvta2bVZtY71eeVGO6uoRUMQAXwzaSy24CtwFmEHwudgCOBowi1\nywOB94EJ0fLtAAeKo+lHgDVAGdAeeBx4pAnL7gN8DoyO5v0jsA24JMVnSSfGPwHdgWJgXe1nByYA\ni4EBQG9gTvg3iH2fA4FNQJeEbX8KlEXTZ0XLGPANYAtweDTvm0BFwrYqgZOi8V8DLwI9gYHAkqRl\nzwP2jf4mF0Yx9I3mXQG8mBTnI8DN0fhpUYzDgI7AfwIvpLNvGrmfuwOrgR8CewF7AyOief8CLAAG\nR59hGNAL+EryvgZerv07R5+tBrgKaEv4Pn4VOAXoEH1P/gb8OuHzLIr2Z5do+WOjeZOB2xPe58fA\n9EL/H7a0oeABaMjTHzp1gnihgfWuA/47Go876P9XwrKjgEVNWPYy4KWEeQasIkWCSDPGoxPm/w9w\nXTQ+h9DUVjvvjOSDVtK2XwMujMZPB96rZ9k/A1dH4/UliI8T/xbA/01cNma7i4BvR+MNJYiHgJ8l\nzNubcN5pQEP7ppH7+f8Ac1Ms90FtvEnl6SSI5Q3EMKb2fYHjgU+AtjHLHQt8CFg0PR84J9v/V3v6\noCYm+XvihJkdbGb/GzUZfAbcAvSpZ/1PEsarqf/EdKpl90uMw8N/dGWqjaQZY1rvBXxUT7wAjwJj\no/ELo+naOM40s9ej5o8NhF/v9e2rWvvWF4OZXWJmC6Jmkg3AwWluF8Ln27k9d/8MWA/0T1gmrb9Z\nA/t5f0IiiFPfvIYkfx/7mdk0M1sRxfBgUgwVHi6IqMPd/0aojRxnZocCBwD/28SYWi0lCEm+xPM+\nwi/Wr7j73sCNhF/0ubSK8AsXADMz6h7QkmUS4yrCgaVWQ5fhTgO+aWb9CU1gj0YxdgL+CPyc0PzT\nA/hLmnF8kioGMzsQuJfQzNI72u67Cdtt6JLclYRmq9rtdSM0Za1II65k9e3nvwMHpVgv1bzNUUyd\nE8r6JS2T/Pl+Qbj67rAohkuSYhhoZm1TxPEw8F1CbWeau3+ZYjlJQQlCknUDNgKbo5N838/De/4Z\nKDWzs8ysHaFduyhHMU4DfmRm/aMTlj+pb2F3/4TQDPIgoXlpaTRrL0K7eBWw3czOJLSVpxvDDWbW\nw8J9IhMS5nUlHCSrCLnye4QaRK3VwIDEk8VJHgMuN7PDzWwvQgJ7yd1T1sjqUd9+ngEcYGYTzGwv\nM9vbzEZE8+4HbjOzgywYZma9CInxE8LFEG3NbDwJyayeGDYDG81sf0IzV61XgbXAzyyc+O9kZscm\nzP8DoUnqQkKykEZSgpBkPwYuJpw0vo9wMjmn3H01cD5wB+Ef/iDgLcIvx2zHeC8wC3gbmEuoBTTk\nUcI5hZ3NS+6+AbgWmE440TuGkOjScROhJlMBzCTh4OXuC4G7gTeiZb4GvJ6w7nPAUmC1mSU2FdWu\n/wyhKWh6tP4BwLg040qWcj+7+0bgVOBcQtJ6Hzgxmv0r4EnCfv6McMK4Y9R0+D3gBsIFC19J+mxx\nbgJGEBLVDOCJhBhqgDOBQwi1iY8Jf4fa+RWEv/OX7v5KIz+7sOsEjkizETUZrATGuPtLhY5HWi4z\ne5hw4vvmQsfSEulGOWkWzGwk4YqhLYTLJLcRfkWLNEl0Pmc0cFihY2mp1MQkzcVxwHJC2/u3gLN1\nUlGaysx+TrgX42fu/nGh42mp1MQkIiKxVIMQEZFYe8w5iD59+nhxcXGhwxARaVHmzZu3xt1jLyvf\nYxJEcXEx5eXlhQ5DRKRFMbOUvQmoiUlERGIpQYiISCwlCBERiaUEISIisZQgREQkVs4ShJk9YGaf\nmtmiFPMterTgMjNbaGalCfMuNrOl0XBxrmIUEcnElClQXAxt2oTXKVPyu36u5bIG8SD1PO+X8HSu\nwdEwntDLJlG3wDcRHnU4ArjJzHrmME4RkUabMgXGj4ePPgL38Dp+fPoH+UzXr91GLhNMzhKEu88h\ndIOcymjgYQ9eA3pYeLj6t4Dn3H2du68ndG9cX6IRkVaqkL/gJ06E6uq6ZdXVoTwf62cjwTSkkOcg\n+lP38YKVUVmq8t2Y2XgzKzez8qqqqpwFKiK5kckButC/4D9O0QVgqvJsr59pgklHiz5J7e6T3b3M\n3cuKiup7AJmINDeZHqAL/Qv+gBQPq01Vnu31M00w6ShkglhB3efyDojKUpWLSDNTyCaaQv+Cv/12\n6Ny5blnnzqE8H+tnmmDS4u45G4BiYFGKed8mPG7RgKOBN6LyXsCHhAet94zGezX0XkcccYSLSOM8\n8oj7wIHuZuH1kUcat27nzu7h938YOndOfxtmddetHczSW3/gwPj1Bw7Mz/rume2/TNfPdP/XAso9\n1TE81YxMB8LD01cRngxWCVwOXAlcGc034B7gA8JzY8sS1r0MWBYNl6bzfkoQIo2T6QGm0AfoTOPP\n1gG2kDJNUO4FShD5HpQgpDXK5ACR6QE60xpANg7QhfwFv6eoL0HsMU+UKysrc3X3La1J7UnexHb8\nzp1h8mQYN67h9du0CYflZGawY0fD6xcXhxPLyQYOhIqKhteH8BkmTgzt/gccENrf04ldssfM5rl7\nWdy8Fn0Vk0hLV8iTvJme5Mz0JCuEZFBRERJSRYWSQ3OjBCFSIIW+Dj/TA/y4caG2MnBgqHUMHJh+\n7UVaBjUxiRRIpk00auKRbFATk0iOZNJEVOgaAKiJR+qnBCHSRJk2EWV6DkBNPJJramISaaJMm3gy\nvQpJJBvUxCSSQiGbiFQDkOauXaEDECmU5F/wtU1EkN5B+oAD4msQjekLZ9w4JQRpvlSDkFYr0/sI\nsnGSWKQ5U4KQVktNRCL1UxOTtFpqIhKpn2oQ0qJlcpJZTUQi9VOCkBYr0/sQ1EQkUj/dByEtVja6\nmhBp7XQfhDRbhbwPQUTqpwQhBVPoripEpH5KEFIwug9BpHlTgpCC0X0IIs2b7oOQgtF9CCLNm2oQ\nUjBqIhJp3pQgpGDURCTSvKmJSQpKTUQizZdqECIiEksJQjKSyY1uItK8qYlJmizTB+6ISPOmGoQ0\nWaY3uolI86YEIU2mvpBE9mxKENJk6gtJZM+mBCFNphvdRPZsShDSZLrRTWTPpquYJCO60U1kz6Ua\nhIiIxFKCaOV0o5uIpKImplZMN7qJSH1Ug2jFdKObiNQnpwnCzEaa2XtmtszMro+ZP9DMZpnZQjN7\n0cwGJMzbbmbzo2FGLuNsrXSjm4jUJ2cJwszaAvcApwMlwFgzK0la7NfAw+5+OHAL8POEeVvcfVg0\njMpVnK2ZbnQTkfrksgYxAljm7svdfSswFRidtEwJ8EI0PjtmvuSQbnQTkfrkMkH0B/6eMF0ZlSVa\nAJwTjZ8NdDOz3tF0RzMrN7PXzOwf4t7AzMZHy5RXVVVlM/ZWQTe6iUh9Cn0V03XAb8zsEmAOsALY\nHs0b6O4rzOxA4AUze9vdP0hc2d0nA5MBysrKPH9h7zl0o5uIpJLLBLEC2D9hekBUtpO7rySqQZhZ\nV+Bcd98QzVsRvS43sxeB4UCdBCEiIrmTyyamucBgMxtkZh2AC4A6VyOZWR8zq43hX4AHovKeZrZX\n7TLAscCSHMbaYulGNxHJlZzVINy9xswmAM8CbYEH3H2xmd0ClLv7DOAk4Odm5oQmpquj1Q8B7jOz\nHYQk9m/urgSRRDe6iUgumfue0XRfVlbm5eXlhQ4jr4qLQ1JINnAgVFTkOxoRaYnMbJ67l8XN053U\nLZhudBORXFKCaMF0o5uI5JISRAumG91EJJeUIFow3egmIrlU6BvlJEO60U1EckU1CBERiaUEISIi\nsZQgREQklhKEiIjEUoIQEZFYShAiIhJLCaLA1BuriDRXug+igNQbq4g0Z6pBFNDEibuSQ63q6lAu\nIlJoShAFpN5YRaQ5U4IoIPXGKiLNmRJEAak3VhFpzpQgCki9sYpIc6armApMvbGKSHOlGoSIiMRS\nghARkVhKECIiEksJQkREYilBiIhILCUIERGJpQQhIiKxlCBERCSWEoSIiMRqMEGY2TVm1jMfwYiI\nSPORTg2iLzDXzKaZ2Ugzs1wHJSIihddggnD3ScBg4HfAJcBSM/uZmR2U49hERKSA0joH4e4OfBIN\nNUBP4I9m9sscxiYiIgXUYG+uZvZD4CJgDXA/8E/uvs3M2gBLgX/ObYgiIlII6XT33Qs4x90/Six0\n9x1mdmZuwhIRkUJLp4lpJrCudsLM9jazowDc/Z1cBSYiIoWVToK4F9iUML0pKhNgyhQoLoY2bcLr\nlCmFjkhEJDvSSRAWnaQGQtMSaT6JLros9j0zW2Zm18fMH2hms8xsoZm9aGYDEuZdbGZLo+HidN4v\n36ZMgfHj4aOPwD28jh+vJCEie4Z0EsRyM/uBmbWPhh8CyxtayczaAvcApwMlwFgzK0la7NfAw+5+\nOHAL8PNo3V7ATcBRwAjgpuZ4s97EiVBdXbesujqUi4i0dOkkiCuBrwMrgErCQXt8GuuNAJa5+3J3\n3wpMBUYnLVMCvBCNz06Y/y3gOXdf5+7rgeeAkWm8Z159/HHjykVEWpJ0bpT71N0vcPd93L2vu1/o\n7p+mse3+wN8TpiujskQLgHOi8bOBbmbWO811MbPxZlZuZuVVVVVphJRdBxzQuHIRkZYknb6YOprZ\n1Wb2n2b2QO2Qpfe/DjjRzN4CTiTUUranu7K7T3b3MncvKyoqylJI6bv9dujcuW5Z586hXESkpUun\niekPQD9Cs89fgQHA52mstwLYP2F6QFS2k7uvdPdz3H04MDEq25DOus3BuHEweTIMHAhm4XXy5FAu\nItLSWcIFSvELmL3l7sPNbKG7H25m7YGX3P3oBtZrB7wPnEI4uM8FLnT3xQnL9AHWRTfd3Q5sd/cb\no5PU84DSaNE3gSPcfR0plJWVeXl5eYMfWEREdjGzee5eFjcvnRrEtuh1g5kdCnQH9mloJXevASYA\nzwLvANPcfbGZ3WJmo6LFTgLeM7P3Cb3G3h6tuw64lZBU5gK31JccREQk+9KpQVwBPAEcBjwIdAV+\n6u735Ty6RlANQkSk8eqrQdR7w1vUId9n0aWmc4ADcxCfiIg0Q/U2MUV3Tau3VhGRViidLjOeN7Pr\ngMeBzbWFOifQPLjDokWwYwfsuy/06RP6hRIRyVQ6CeL86PXqhDJHzU0FtWULTJ0Kv/kNvPnmrvK2\nbaFvX+jXLySM+l47dSpc/CLS/DWYINx9UD4CaclefBH694fBg3P/XhUVcO+9cP/9sG4dlJSEJNG3\nL3zyCaxatet15UqYNw8+/TTUMJJ1774rYfTtGz/06wf77AN77ZX7zyYizUs6T5S7KK7c3R/Ofjgt\nzwMPwOWXh/GDD4ZRo+Css+CYY8Kv+Wxwh1mzQiJ46qlQ9g//ABMmwEknhZv06rN9O1RV7Z5Aal9X\nrQqJZPVq+DzFLZA9etSfRIYNg/33j19XRFqmdC5zvTthsiPhxrc33X1MLgNrrEJc5vrSS3DKKXDC\nCTB6NMyYEWoTNTXhXMC3vx0SxmmnQdeujd/+Z5/Bww/DPffAu++GbY4fD9//fu76e9qyJSSKuOGT\nT+pOb9xYd92DDoKTTw5J6+STYb/9chOjiGRPfZe5NpggYjbWA5jq7s2qd9V8J4iKCjjySOjVC157\nDXpGnZFv3AjPPhuSxf/+L2zYAB06hEQyahSceSYMGFDvpnn33VBbeOgh2LQpvM8118B3vgMdO+b8\no6Xtiy9C89XKlWEfzJ4Nf/3rrsTx1a+GRFGbNPr2LWi4IhIj2wmiPbDI3b+WjeCyJZ8J4vPP4etf\nh8pKeP31cCCMs20b/O1voVnoT3+CDz4I5aWlIVmMGhWaZsxCM9Cf/xwSw/PPh6Ry/vmhGWnEiLx8\nrKzYvh3mzw81qdmzYc6cXc1WJSW7ahcnnRRqRCJSWBklCDN7inDVEoT7JkoI3Wbs9oS4QspXgti+\nHc4+G55+GmbOhFNPTW8991AzmDEjDK++GsoGDAi1ixdfDE+kGzAArroKrrginBxu6WpqwlVWs2eH\n4eWXYXN0sfRhh+1KFv37h3M2tUObNnWnk4fE+e3ahSuyGjoXIyK7yzRBnJgwWQN85O6VWYwvK/KV\nIK6/Hn7xC7j77vDrvqk+/TQkmRkzwgno0tLQjDRqVDjg7am2bYPy8l0J429/C+c9MlVUFGpjw4fv\nGgYP1j0hIg3JNEEMAla5+xfRdCegr7tXZDvQTOQjQfzhD3DRReEk8b336hdrNnz5ZbiCav36UDtL\nHHbs2L0sbplt22DpUnjrrXDT4Laoe8kuXWDo0LpJY8gQXbIrkijTBFEOfD16bChm1gH4m7sfmfVI\nM5DrBPHqq6Ep5Otfh7/8Bdq3z9lbSQa2boUlS0KyqB3mzw8n+yHUzoYMqZs0hg6FvfcubNwihZJp\ngpjv7sOSyha4+9AsxpixXCaIjz8OVxJ16xZOSvfunZO3kRzZsSNcIJCYNN56KzTz1RoxIlwlNmYM\nFBcXLFSRvGtyb66RKjMb5e4zoo2NBtZkM8DmbPPmcI/DF1+EE8lKDi1PmzbhfMTgwXDeeaHMPdwg\n+NZboYlrxgz4p38Kw5FH7koWg9SPgLRi6dQgDgKmALW3PVUCF7n7shzH1ii5qEHs2BEOFE8+GS5B\nPf30rG5empnly+GPf4T//u9wIh2grCx8B77zHSUL2TNl5T4IM+sK4O6bshhb1uQiQdx4I9x6K9xx\nB1x7bVY3Lc3chx/uShZz54ayI47YlSwObAZdVe7YEWq21dXhTv3mdBOltByZnoP4GfBLd98QTfcE\nfuzuk7IeaQaynSCmToWxY+Gyy0LHeLpiqfWqqNiVLN54I5SVlu5KFgcdlHpd93AA//zz+ofq6rrD\n5s27lyUPyZcH9+oV7qPp33/Xa/J4z576LktdmSaIt9x9eFLZm+5emsUYM5bNBDF3buhf6cgjd93V\nLALhZsbaZPH666Fs+PDQN1bcgX/TpviedON06ACdOzc8dOlSd7pTp9Bv14oVYaisDK+rV+/+Hp06\n7Z44BgwISW7IkPA5lEBal0wTxELgSHf/MpruBJS7+5CsR5qBbCWIFStCYthrr/BrsagoC8HJHunj\nj0OymD499D/VrVvThy5dsn+D5Nat4UR8YtJIfl2xYtd9IxCaqkpK4NBDQ8KoHfr3z27i+OKL0IdX\nbRzbtjWcEDt12rNvIi2UTBPET4CzgN8DBlwCzHD3X2Y5zoxkI0FUV8OJJ4YuMV55JXQFIbIn27Ej\ndAW/dCksXhxuNFy8OAyJlwF37143YQwZEpJI3751E4d7SJZxiSixbO3apsWbqpbVo0fo2yt5KCra\nNd6rlxJMnIxPUpvZSOCbhD6ZPgP6ufvV9a+VX5kmCPdwzmHatNCx3llnZTE4kRaoqmpXskgcEg/u\nvXqFZNGu3a4EUF29+7aKiuo/N9KxY/x5lnTOxWzeHJJSVRWsWbPrpsg4PXvunjj69Am1lHT7/oob\niorgkENaZgeUmd4HAbCakBy+A3wIPJGl2JqN226Dxx8P/SwpOYiEg95JJ4Whlns4t5GcNL78MvSF\ndeaZuyeA/fbLb/cmX3wRktiaNWGoTRzJw0cfhcuZ16wJzXHZUFQUmuhKSkLCqB3v169lnttJWYMw\ns68CY6NhDfA4cJ27D8xfeOnLpAbxxBPhpqiLLoIHH2yZf0gRaRr39Pr+qm/+J5+ELl4Shw0bdr1H\njx51E0ZtAtl//8J3KNmkJiYz2wG8BFxee1OcmS1392ZwBfjumpog3n8//PIZNgxeeEHXkotI5mpr\nWslJ45136p7b6dIlJIqiotA1fu2wbVvjxsvKwrNXmqKpTUznABcAs83sGWAq4ST1HuUrX4FJk8L9\nDkoOIpINZqFZqV8/+MY36s5bsyYkisTE8emnoQPQdu3C0LFjeE0sq288V/2HpXMVUxdgNKGp6RvA\nw8B0d/9LbkJqmkI8k1pEpKWrrwbRYOuXu29290fd/SxgAPAW8JMsxygiIs1Mo06PuPt6d5/s7qfk\nKiAREWke9EBGERGJpQQhIiKxlCBERCSWEoSIiMRSghARkVhKECIiEksJQkREYuU0QZjZSDN7z8yW\nmdn1MfMPMLPZZvaWmS00szOi8mIz22Jm86Phv3IZp4iI7C5nj88ws7bAPcCpQCUw18xmuPuShMUm\nAdPc/V4zKwGeBoqjeR+4+7BcxSciIvXLZQ1iBLDM3Ze7+1ZCZ3+jk5ZxYO9ovDuwMofxiIhII+Qy\nQfQH/p4wXRmVJboZ+K6ZVRJqD9ckzBsUNT391cyOj3sDMxtvZuVmVl5VVZXF0EVEpNAnqccCD7r7\nAOAM4A9m1gZYBRzg7sOBfwQeNbO9k1eO+oUqc/eyoqKivAYuIrKny2WCWAHsnzA9ICpLdDkwDcDd\nXwU6An3c/Ut3XxuVzwM+AL6aw1hFRCRJLhPEXGCwmQ0ysw6Ehw/NSFrmY+AUADM7hJAgqsysKDrJ\njZkdCAwGlucwVhERSZKzq5jcvcbMJgDPAm2BB9x9sZndApS7+wzgx8BvzexawgnrS9zdzewE4BYz\n2wbsAK5093W5ilVERHbX4BPlWgo9UU5EpPEyeqKciIi0TkoQIiISSwlCRERiKUGIiEgsJQgREYml\nBCEiIrGUIEREJJYShIiIxFKCEBGRWEoQIiISSwlCRERiKUGIiEgsJQgREYmlBCEiIrGUIEREJJYS\nhIiIxFKCEBGRWEoQIiISSwlCRERiKUGIiEgsJQgREYmlBCEiIrGUIEREJJYShIiIxFKCEBGRWEoQ\nIiISSwlCRERiKUGIiEgsJQgREYnVrtABiEjLt23bNiorK/niiy8KHYqk0LFjRwYMGED79u3TXkcJ\nQkQyVllZSbdu3SguLsbMCh2OJHF31q5dS2VlJYMGDUp7PTUxiUjGvvjiC3r37q3k0EyZGb179250\nDU8JQkSyQsmheWvK30cJQkREYilBiEjeTZkCxcXQpk14nTIls+2tXbuWYcOGMWzYMPr160f//v13\nTm/dujWtbVx66aW899579S5zzz33MCXTYFsQnaQWkbyaMgXGj4fq6jD90UdhGmDcuKZts3fv3syf\nPx+Am2++ma5du3LdddfVWcbdcXfatIn/Xfz73/++wfe5+uqrmxZgC5XTGoSZjTSz98xsmZldHzP/\nADObbWZvmdlCMzsjYd6/ROu9Z2bfymWcIpI/EyfuSg61qqtDebYtW7aMkpISxo0bx5AhQ1i1ahXj\nx4+nrKyMIUOGcMstt+xc9rjjjmP+/PnU1NTQo0cPrr/+eoYOHcoxxxzDp59+CsCkSZO48847dy5/\n/fXXM2LECL72ta/xyiuvALB582bOPfdcSkpKGDNmDGVlZTuTV6KbbrqJI488kkMPPZQrr7wSdwfg\n/fff5xvf+AZDhw6ltLSUiooKAH72s59x2GGHMXToUCbmYmfFyFmCMLO2wD3A6UAJMNbMSpIWmwRM\nc/fhwAXAf0brlkTTQ4CRwH9G2xORFu7jjxtXnql3332Xa6+9liVLltC/f3/+7d/+jfLychYsWMBz\nzz3HkiVLdltn48aNnHjiiSxYsIBjjjmGBx54IHbb7s4bb7zBr371q53J5u6776Zfv34sWbKEn/70\np7z11lux6/7whz9k7ty5vP3222zcuJFnnnkGgLFjx3LttdeyYMECXnnlFfbZZx+eeuopZs6cyRtv\nvMGCBQv48Y9/nKW9U79c1iBGAMvcfbm7bwWmAqOTlnFg72i8O7AyGh8NTHX3L939Q2BZtD0RaeEO\nOKBx5Zk66KCDKCsr2zn92GOPUVpaSmlpKe+8805sgujUqROnn346AEccccTOX/HJzjnnnN2Wefnl\nl7ngggsAGDp0KEOGDIldd9asWYwYMYKhQ4fy17/+lcWLF7N+/XrWrFnDWWedBYSb2zp37szzzz/P\nZZddRqdOnQDo1atX43dEE+QyQfQH/p4wXRmVJboZ+K6ZVQJPA9c0Yl3MbLyZlZtZeVVVVbbiFpEc\nuv126Ny5blnnzqE8F7p06bJzfOnSpfzHf/wHL7zwAgsXLmTkyJGx9wZ06NBh53jbtm2pqamJ3fZe\ne+3V4DJxqqurmTBhAtOnT2fhwoVcdtllzfIu9EJfxTQWeNDdBwBnAH8ws7RjcvfJ7l7m7mVFRUU5\nC1JEsmfcOJg8GQYOBLPwOnly009QN8Znn31Gt27d2HvvvVm1ahXPPvts1t/j2GOPZdq0aQC8/fbb\nsTWULVu20KZNG/r06cPnn1a3jIIAAA1/SURBVH/OE088AUDPnj0pKiriqaeeAsINiNXV1Zx66qk8\n8MADbNmyBYB169ZlPe44ubyKaQWwf8L0gKgs0eWEcwy4+6tm1hHok+a6ItJCjRuXn4SQrLS0lJKS\nEg4++GAGDhzIsccem/X3uOaaa7jooosoKSnZOXTv3r3OMr179+biiy+mpKSEfffdl6OOOmrnvClT\npvD973+fiRMn0qFDB5544gnOPPNMFixYQFlZGe3bt+ess87i1ltvzXrsyaz2zHnWN2zWDngfOIVw\ncJ8LXOjuixOWmQk87u4PmtkhwCxCU1IJ8CjhvMN+Uflgd9+e6v3Kysq8vLw8J59FROr3zjvvcMgh\nhxQ6jGahpqaGmpoaOnbsyNKlSznttNNYunQp7doV/q6CuL+Tmc1z97K45XMWsbvXmNkE4FmgLfCA\nuy82s1uAcnefAfwY+K2ZXUs4YX2Jh4y12MymAUuAGuDq+pKDiEhzsWnTJk455RRqampwd+67775m\nkRyaIqdRu/vThJPPiWU3JowvAWLreO5+O5Cj01YiIrnRo0cP5s2bV+gwsqLQJ6lFRKSZUoIQEZFY\nShAiIhJLCUJERGIpQYhIi3fyySfvdtPbnXfeyVVXXVXvel27dgVg5cqVjBkzJnaZk046iYYuob/z\nzjupTuiB8IwzzmDDhg3phN6sKUGISIs3duxYpk6dWqds6tSpjB07Nq3199tvP/74xz82+f2TE8TT\nTz9Njx49mry95qJlXpwrIs3Wj34EMb1bZ2TYMIh62Y41ZswYJk2axNatW+nQoQMVFRWsXLmS448/\nnk2bNjF69GjWr1/Ptm3buO222xg9um6/oRUVFZx55pksWrSILVu2cOmll7JgwQIOPvjgnd1bAFx1\n1VXMnTuXLVu2MGbMGP71X/+Vu+66i5UrV3LyySfTp08fZs+eTXFxMeXl5fTp04c77rhjZ2+wV1xx\nBT/60Y+oqKjg9NNP57jjjuOVV16hf//+/OlPf9rZGV+tp556ittuu42tW7fSu3dvpkyZQt++fdm0\naRPXXHMN5eXlmBk33XQT5557Ls888ww33HAD27dvp0+fPsyaNSuj/a4EISItXq9evRgxYgQzZ85k\n9OjRTJ06lfPOOw8zo2PHjkyfPp29996bNWvWcPTRRzNq1KiUz2i+99576dy5M++88w4LFy6ktLR0\n57zbb7+dXr16sX37dk455RQWLlzID37wA+644w5mz55Nnz596mxr3rx5/P73v+f111/H3TnqqKM4\n8cQT6dmzJ0uXLuWxxx7jt7/9Leeddx5PPPEE3/3ud+usf9xxx/Haa69hZtx///388pe/5N///d+5\n9dZb6d69O2+//TYA69evp6qqiu9973vMmTOHQYMGZaW/JiUIEcmq+n7p51JtM1Ntgvjd734HhGc2\n3HDDDcyZM4c2bdqwYsUKVq9eTb9+/WK3M2fOHH7wgx8AcPjhh3P44YfvnDdt2jQmT55MTU0Nq1at\nYsmSJXXmJ3v55Zc5++yzd/Yoe8455/DSSy8xatQoBg0axLBhw4DUXYpXVlZy/vnns2rVKrZu3cqg\nQYMAeP755+s0qfXs2ZOnnnqKE044Yecy2egSvNWfg8j2s3FFpDBGjx7NrFmzePPNN6muruaII44A\nQud3VVVVzJs3j/nz59O3b98mda394Ycf8utf/5pZs2axcOFCvv3tb2fURXdtV+GQurvwa665hgkT\nJvD2229z33335b1L8FadIGqfjfvRR+C+69m4ShIiLU/Xrl05+eSTueyyy+qcnN64cSP77LMP7du3\nZ/bs2Xz00Uf1bueEE07g0UcfBWDRokUsXLgQCF2Fd+nShe7du7N69Wpmzpy5c51u3brx+eef77at\n448/nieffJLq6mo2b97M9OnTOf7449P+TBs3bqR///AonIceemhn+amnnso999yzc3r9+vUcffTR\nzJkzhw8//BDITpfgrTpB5PPZuCKSe2PHjmXBggV1EsS4ceMoLy/nsMMO4+GHH+bggw+udxtXXXUV\nmzZt4pBDDuHGG2/cWRMZOnQow4cP5+CDD+bCCy+s01X4+PHjGTlyJCeffHKdbZWWlnLJJZcwYsQI\njjrqKK644gqGDx+e9ue5+eab+c53vsMRRxxR5/zGpEmTWL9+PYceeihDhw5l9uzZFBUVMXnyZM45\n5xyGDh3K+eefn/b7pJKz7r7zrSndfbdpE2oOycxgx44sBSbSCqi775ahsd19t+oaRL6fjSsi0pK0\n6gSR72fjioi0JK06QRTy2bgie5o9pbl6T9WUv0+rvw+iUM/GFdmTdOzYkbVr19K7d++UN6BJ4bg7\na9eupWPHjo1ar9UnCBHJ3IABA6isrKSqqqrQoUgKHTt2ZMCAAY1aRwlCRDLWvn37nXfwyp6jVZ+D\nEBGR1JQgREQklhKEiIjE2mPupDazKqD+TlYKqw+wptBB1EPxZUbxZUbxZSaT+Aa6e1HcjD0mQTR3\nZlae6nb25kDxZUbxZUbxZSZX8amJSUREYilBiIhILCWI/Jlc6AAaoPgyo/gyo/gyk5P4dA5CRERi\nqQYhIiKxlCBERCSWEkSWmNn+ZjbbzJaY2WIz+2HMMieZ2UYzmx8NNxYgzgozezt6/90ewWfBXWa2\nzMwWmllpHmP7WsK+mW9mn5nZj5KWyes+NLMHzOxTM1uUUNbLzJ4zs6XRa88U614cLbPUzC7OY3y/\nMrN3o7/fdDPrkWLder8LOYzvZjNbkfA3PCPFuiPN7L3ou3h9HuN7PCG2CjObn2LdfOy/2ONK3r6D\n7q4hCwOwL1AajXcD3gdKkpY5CfhzgeOsAPrUM/8MYCZgwNHA6wWKsy3wCeEmnoLtQ+AEoBRYlFD2\nS+D6aPx64Bcx6/UClkevPaPxnnmK7zSgXTT+i7j40vku5DC+m4Hr0vj7fwAcCHQAFiT/P+UqvqT5\n/w7cWMD9F3tcydd3UDWILHH3Ve7+ZjT+OfAO0L+wUTXJaOBhD14DepjZvgWI4xTgA3cv6N3x7j4H\nWJdUPBp4KBp/CPiHmFW/BTzn7uvcfT3wHDAyH/G5+1/cvSaafA1oXB/PWZRi/6VjBLDM3Ze7+1Zg\nKmG/Z1V98Vl4sMV5wGPZft901XNcyct3UAkiB8ysGBgOvB4z+xgzW2BmM81sSF4DCxz4i5nNM7Px\nMfP7A39PmK6kMInuAlL/YxZ6H/Z191XR+CdA35hlmst+vIxQI4zT0HchlyZETWAPpGgeaQ7773hg\ntbsvTTE/r/sv6biSl++gEkSWmVlX4AngR+7+WdLsNwlNJkOBu4En8x0fcJy7lwKnA1eb2QkFiKFe\nZtYBGAX8d8zs5rAPd/JQl2+W14qb2USgBpiSYpFCfRfuBQ4ChgGrCM04zdFY6q895G3/1XdcyeV3\nUAkii8ysPeGPOMXd/yd5vrt/5u6bovGngfZm1iefMbr7iuj1U2A6oSqfaAWwf8L0gKgsn04H3nT3\n1ckzmsM+BFbXNrtFr5/GLFPQ/WhmlwBnAuOiA8hu0vgu5IS7r3b37e6+A/htivct9P5rB5wDPJ5q\nmXztvxTHlbx8B5UgsiRqr/wd8I6735FimX7RcpjZCML+X5vHGLuYWbfaccLJzEVJi80ALoquZjoa\n2JhQlc2XlL/cCr0PIzOA2itCLgb+FLPMs8BpZtYzakI5LSrLOTMbCfwzMMrdq1Msk853IVfxJZ7T\nOjvF+84FBpvZoKhGeQFhv+fLN4F33b0ybma+9l89x5X8fAdzeQa+NQ3AcYRq3kJgfjScAVwJXBkt\nMwFYTLgi4zXg63mO8cDovRdEcUyMyhNjNOAewhUkbwNleY6xC+GA3z2hrGD7kJCoVgHbCG24lwO9\ngVnAUuB5oFe0bBlwf8K6lwHLouHSPMa3jND2XPs9/K9o2f2Ap+v7LuQpvj9E362FhAPdvsnxRdNn\nEK7a+SCf8UXlD9Z+5xKWLcT+S3Vcyct3UF1tiIhILDUxiYhILCUIERGJpQQhIiKxlCBERCSWEoSI\niMRSghBpgJltt7q9zGatZ1EzK07sSVSkOWlX6ABEWoAt7j6s0EGI5JtqECJNFD0P4JfRMwHeMLOv\nROXFZvZC1BndLDM7ICrva+H5DAui4evRptqa2W+j/v7/YmadouV/ED0HYKGZTS3Qx5RWTAlCpGGd\nkpqYzk+Yt9HdDwN+A9wZld0NPOTuhxM6yrsrKr8L+KuHjgZLCXfgAgwG7nH3IcAG4Nyo/HpgeLSd\nK3P14URS0Z3UIg0ws03u3jWmvAL4hrsvjzpU+8Tde5vZGkL3Edui8lXu3sfMqoAB7v5lwjaKCX32\nD46mfwK0d/fbzOwZYBOhx9onPeqkUCRfVIMQyYynGG+MLxPGt7Pr3OC3Cf1ilQJzox5GRfJGCUIk\nM+cnvL4ajb9C6H0UYBzwUjQ+C7gKwMzamln3VBs1szbA/u4+G/gJ0B3YrRYjkkv6RSLSsE5W98H1\nz7h77aWuPc1sIaEWMDYquwb4vZn9E1AFXBqV/xCYbGaXE2oKVxF6Eo3TFngkSiIG3OXuG7L2iUTS\noHMQIk0UnYMoc/c1hY5FJBfUxCQiIrFUgxARkViqQYiISCwlCBERiaUEISIisZQgREQklhKEiIjE\n+v/Q26xA3wekMAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvIHP0TI10i_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "a9c8ee59-22a6-4e3d-f797-b2c3ea69ce72"
      },
      "source": [
        "model.predict(x_test)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00263584],\n",
              "       [0.99999964],\n",
              "       [0.10760641],\n",
              "       ...,\n",
              "       [0.00234881],\n",
              "       [0.00725222],\n",
              "       [0.5632432 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0xcXDWp2wG6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "outputId": "4f344f13-b9ae-40ba-fee8-4e66c8eeab1e"
      },
      "source": [
        "# 1개의 hidden layer\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu',input_shape=(10000,)))\n",
        "# model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))\n",
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 1s 90us/step - loss: 0.5110 - acc: 0.7970 - val_loss: 0.4011 - val_acc: 0.8689\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.3309 - acc: 0.9007 - val_loss: 0.3269 - val_acc: 0.8828\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 1s 75us/step - loss: 0.2568 - acc: 0.9223 - val_loss: 0.2937 - val_acc: 0.8897\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 1s 75us/step - loss: 0.2104 - acc: 0.9363 - val_loss: 0.2787 - val_acc: 0.8904\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 1s 75us/step - loss: 0.1782 - acc: 0.9458 - val_loss: 0.2729 - val_acc: 0.8903\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 1s 77us/step - loss: 0.1550 - acc: 0.9551 - val_loss: 0.2739 - val_acc: 0.8902\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.1363 - acc: 0.9614 - val_loss: 0.2807 - val_acc: 0.8873\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 1s 75us/step - loss: 0.1200 - acc: 0.9648 - val_loss: 0.2906 - val_acc: 0.8863\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 1s 77us/step - loss: 0.1059 - acc: 0.9713 - val_loss: 0.2914 - val_acc: 0.8863\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 1s 75us/step - loss: 0.0941 - acc: 0.9755 - val_loss: 0.3026 - val_acc: 0.8831\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 1s 77us/step - loss: 0.0835 - acc: 0.9787 - val_loss: 0.3201 - val_acc: 0.8840\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 1s 78us/step - loss: 0.0743 - acc: 0.9809 - val_loss: 0.3305 - val_acc: 0.8824\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0661 - acc: 0.9840 - val_loss: 0.3370 - val_acc: 0.8803\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 1s 77us/step - loss: 0.0585 - acc: 0.9881 - val_loss: 0.3607 - val_acc: 0.8757\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0522 - acc: 0.9889 - val_loss: 0.3688 - val_acc: 0.8775\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 1s 75us/step - loss: 0.0465 - acc: 0.9913 - val_loss: 0.3819 - val_acc: 0.8771\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 1s 77us/step - loss: 0.0400 - acc: 0.9931 - val_loss: 0.4094 - val_acc: 0.8739\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 1s 77us/step - loss: 0.0361 - acc: 0.9945 - val_loss: 0.4141 - val_acc: 0.8750\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0318 - acc: 0.9952 - val_loss: 0.4351 - val_acc: 0.8708\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0278 - acc: 0.9962 - val_loss: 0.4495 - val_acc: 0.8708\n",
            "25000/25000 [==============================] - 2s 76us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4880905333566666, 0.8594]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDVz--X-3P25",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "outputId": "e585b0ac-ed8b-442f-f56f-cd15e2414167"
      },
      "source": [
        "# 3개의 hidden layer\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu',input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))\n",
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 1s 94us/step - loss: 0.5377 - acc: 0.7681 - val_loss: 0.4006 - val_acc: 0.8611\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 1s 78us/step - loss: 0.3136 - acc: 0.8999 - val_loss: 0.3684 - val_acc: 0.8465\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 1s 77us/step - loss: 0.2215 - acc: 0.9270 - val_loss: 0.2963 - val_acc: 0.8854\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.1706 - acc: 0.9455 - val_loss: 0.3455 - val_acc: 0.8679\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 1s 78us/step - loss: 0.1397 - acc: 0.9559 - val_loss: 0.2937 - val_acc: 0.8861\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.1136 - acc: 0.9650 - val_loss: 0.3135 - val_acc: 0.8851\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 1s 77us/step - loss: 0.0880 - acc: 0.9742 - val_loss: 0.3380 - val_acc: 0.8789\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0708 - acc: 0.9813 - val_loss: 0.3789 - val_acc: 0.8784\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 1s 77us/step - loss: 0.0598 - acc: 0.9844 - val_loss: 0.3923 - val_acc: 0.8795\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 1s 77us/step - loss: 0.0478 - acc: 0.9881 - val_loss: 0.4303 - val_acc: 0.8782\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0412 - acc: 0.9890 - val_loss: 0.4506 - val_acc: 0.8762\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0305 - acc: 0.9929 - val_loss: 0.5019 - val_acc: 0.8726\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 1s 77us/step - loss: 0.0223 - acc: 0.9951 - val_loss: 0.5151 - val_acc: 0.8729\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 1s 78us/step - loss: 0.0205 - acc: 0.9955 - val_loss: 0.5705 - val_acc: 0.8719\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 1s 78us/step - loss: 0.0100 - acc: 0.9989 - val_loss: 0.5692 - val_acc: 0.8702\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 1s 75us/step - loss: 0.0171 - acc: 0.9953 - val_loss: 0.6084 - val_acc: 0.8700\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 1s 77us/step - loss: 0.0060 - acc: 0.9995 - val_loss: 0.6267 - val_acc: 0.8691\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 1s 77us/step - loss: 0.0124 - acc: 0.9963 - val_loss: 0.6680 - val_acc: 0.8694\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0034 - acc: 0.9996 - val_loss: 0.6957 - val_acc: 0.8698\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 1s 78us/step - loss: 0.0131 - acc: 0.9962 - val_loss: 0.7283 - val_acc: 0.8677\n",
            "25000/25000 [==============================] - 2s 76us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8116433194971084, 0.85092]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiPsRpEm3k9f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "outputId": "6d7c8446-0192-4f52-9921-ff75b35c31ae"
      },
      "source": [
        "# 2개의 hidden layer\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu',input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "# model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))\n",
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 0.5178 - acc: 0.7836 - val_loss: 0.3981 - val_acc: 0.8546\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.3063 - acc: 0.9030 - val_loss: 0.3087 - val_acc: 0.8851\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 1s 78us/step - loss: 0.2226 - acc: 0.9299 - val_loss: 0.2772 - val_acc: 0.8909\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 1s 78us/step - loss: 0.1727 - acc: 0.9451 - val_loss: 0.2944 - val_acc: 0.8803\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 1s 82us/step - loss: 0.1420 - acc: 0.9556 - val_loss: 0.2813 - val_acc: 0.8873\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 1s 77us/step - loss: 0.1152 - acc: 0.9655 - val_loss: 0.2958 - val_acc: 0.8851\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 1s 78us/step - loss: 0.0939 - acc: 0.9737 - val_loss: 0.3107 - val_acc: 0.8844\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0775 - acc: 0.9792 - val_loss: 0.3588 - val_acc: 0.8760\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 1s 78us/step - loss: 0.0658 - acc: 0.9828 - val_loss: 0.3548 - val_acc: 0.8793\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 1s 74us/step - loss: 0.0513 - acc: 0.9876 - val_loss: 0.3877 - val_acc: 0.8752\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 1s 75us/step - loss: 0.0425 - acc: 0.9909 - val_loss: 0.4051 - val_acc: 0.8753\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 1s 75us/step - loss: 0.0330 - acc: 0.9930 - val_loss: 0.4309 - val_acc: 0.8748\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0284 - acc: 0.9935 - val_loss: 0.4638 - val_acc: 0.8737\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0202 - acc: 0.9967 - val_loss: 0.4904 - val_acc: 0.8741\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 1s 77us/step - loss: 0.0164 - acc: 0.9973 - val_loss: 0.5187 - val_acc: 0.8718\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0104 - acc: 0.9993 - val_loss: 0.5559 - val_acc: 0.8704\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0127 - acc: 0.9980 - val_loss: 0.5829 - val_acc: 0.8715\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 1s 75us/step - loss: 0.0088 - acc: 0.9985 - val_loss: 0.6187 - val_acc: 0.8684\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 1s 75us/step - loss: 0.0042 - acc: 0.9999 - val_loss: 0.6447 - val_acc: 0.8684\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0056 - acc: 0.9995 - val_loss: 0.6665 - val_acc: 0.8686\n",
            "25000/25000 [==============================] - 2s 74us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7374479610776902, 0.85232]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AgfxZJE3ylH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "outputId": "244ee019-c2ad-4b49-f8d8-03ce221156d0"
      },
      "source": [
        "# 1개의 hidden layer 32개 노드\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(32, activation='relu',input_shape=(10000,)))\n",
        "# model.add(layers.Dense(16, activation='relu'))\n",
        "# model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))\n",
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 1s 99us/step - loss: 0.4708 - acc: 0.8062 - val_loss: 0.3628 - val_acc: 0.8667\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 1s 77us/step - loss: 0.2862 - acc: 0.9072 - val_loss: 0.3034 - val_acc: 0.8859\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.2196 - acc: 0.9281 - val_loss: 0.2811 - val_acc: 0.8881\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.1772 - acc: 0.9431 - val_loss: 0.2951 - val_acc: 0.8797\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 1s 79us/step - loss: 0.1491 - acc: 0.9543 - val_loss: 0.2821 - val_acc: 0.8867\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.1269 - acc: 0.9631 - val_loss: 0.2852 - val_acc: 0.8857\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 1s 75us/step - loss: 0.1080 - acc: 0.9678 - val_loss: 0.3488 - val_acc: 0.8669\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 1s 75us/step - loss: 0.0958 - acc: 0.9732 - val_loss: 0.3196 - val_acc: 0.8791\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0799 - acc: 0.9788 - val_loss: 0.3335 - val_acc: 0.8749\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0692 - acc: 0.9832 - val_loss: 0.3418 - val_acc: 0.8769\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0602 - acc: 0.9865 - val_loss: 0.3778 - val_acc: 0.8705\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 1s 78us/step - loss: 0.0517 - acc: 0.9883 - val_loss: 0.3748 - val_acc: 0.8785\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 1s 78us/step - loss: 0.0433 - acc: 0.9913 - val_loss: 0.4330 - val_acc: 0.8721\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 1s 80us/step - loss: 0.0364 - acc: 0.9937 - val_loss: 0.4211 - val_acc: 0.8749\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 1s 80us/step - loss: 0.0320 - acc: 0.9944 - val_loss: 0.4423 - val_acc: 0.8713\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 1s 79us/step - loss: 0.0267 - acc: 0.9962 - val_loss: 0.4898 - val_acc: 0.8636\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 1s 80us/step - loss: 0.0227 - acc: 0.9971 - val_loss: 0.4943 - val_acc: 0.8679\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 1s 79us/step - loss: 0.0183 - acc: 0.9979 - val_loss: 0.5233 - val_acc: 0.8687\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 1s 77us/step - loss: 0.0161 - acc: 0.9987 - val_loss: 0.5420 - val_acc: 0.8651\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0131 - acc: 0.9993 - val_loss: 0.5670 - val_acc: 0.8655\n",
            "25000/25000 [==============================] - 2s 70us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.614616737279892, 0.85264]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WhnwHyB3-1j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "outputId": "aeef7db0-f887-4176-f09f-6f3b31ea88dd"
      },
      "source": [
        "# 1개의 hidden layer 64개 노드\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu',input_shape=(10000,)))\n",
        "# model.add(layers.Dense(16, activation='relu'))\n",
        "# model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))\n",
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 2s 102us/step - loss: 0.4786 - acc: 0.7855 - val_loss: 0.3355 - val_acc: 0.8781\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 1s 77us/step - loss: 0.2643 - acc: 0.9093 - val_loss: 0.3110 - val_acc: 0.8733\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.1987 - acc: 0.9321 - val_loss: 0.2781 - val_acc: 0.8879\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 1s 78us/step - loss: 0.1551 - acc: 0.9512 - val_loss: 0.2997 - val_acc: 0.8795\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 1s 77us/step - loss: 0.1341 - acc: 0.9544 - val_loss: 0.2859 - val_acc: 0.8873\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 1s 77us/step - loss: 0.1102 - acc: 0.9651 - val_loss: 0.3000 - val_acc: 0.8856\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 1s 77us/step - loss: 0.0901 - acc: 0.9727 - val_loss: 0.3350 - val_acc: 0.8739\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 1s 77us/step - loss: 0.0760 - acc: 0.9787 - val_loss: 0.3383 - val_acc: 0.8784\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0624 - acc: 0.9846 - val_loss: 0.3741 - val_acc: 0.8757\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 1s 78us/step - loss: 0.0561 - acc: 0.9861 - val_loss: 0.3859 - val_acc: 0.8774\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 1s 77us/step - loss: 0.0454 - acc: 0.9890 - val_loss: 0.4012 - val_acc: 0.8760\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 1s 77us/step - loss: 0.0363 - acc: 0.9925 - val_loss: 0.4247 - val_acc: 0.8738\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 1s 75us/step - loss: 0.0319 - acc: 0.9933 - val_loss: 0.4474 - val_acc: 0.8712\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0253 - acc: 0.9963 - val_loss: 0.4738 - val_acc: 0.8712\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 1s 78us/step - loss: 0.0209 - acc: 0.9971 - val_loss: 0.5006 - val_acc: 0.8704\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0205 - acc: 0.9965 - val_loss: 0.5275 - val_acc: 0.8701\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 1s 77us/step - loss: 0.0124 - acc: 0.9990 - val_loss: 0.5722 - val_acc: 0.8674\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0138 - acc: 0.9980 - val_loss: 0.5757 - val_acc: 0.8681\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0076 - acc: 0.9997 - val_loss: 0.6190 - val_acc: 0.8662\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 1s 78us/step - loss: 0.0084 - acc: 0.9994 - val_loss: 0.6369 - val_acc: 0.8641\n",
            "25000/25000 [==============================] - 2s 70us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7110301396512986, 0.8466]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjeYkIPf4JX3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "outputId": "5cfe43ac-39ab-46ed-e3b0-b5eb39463134"
      },
      "source": [
        "# 1개의 hidden layer 16개 노드, mse\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu',input_shape=(10000,)))\n",
        "# model.add(layers.Dense(16, activation='relu'))\n",
        "# model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='mse',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))\n",
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 1s 100us/step - loss: 0.1641 - acc: 0.7957 - val_loss: 0.1203 - val_acc: 0.8723\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0945 - acc: 0.9060 - val_loss: 0.1020 - val_acc: 0.8743\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0709 - acc: 0.9301 - val_loss: 0.0889 - val_acc: 0.8910\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0572 - acc: 0.9437 - val_loss: 0.0864 - val_acc: 0.8878\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 1s 75us/step - loss: 0.0475 - acc: 0.9540 - val_loss: 0.0861 - val_acc: 0.8870\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0405 - acc: 0.9626 - val_loss: 0.0849 - val_acc: 0.8871\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 1s 74us/step - loss: 0.0354 - acc: 0.9680 - val_loss: 0.0878 - val_acc: 0.8807\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 1s 75us/step - loss: 0.0302 - acc: 0.9739 - val_loss: 0.0858 - val_acc: 0.8822\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0269 - acc: 0.9773 - val_loss: 0.0860 - val_acc: 0.8815\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 1s 75us/step - loss: 0.0232 - acc: 0.9822 - val_loss: 0.0878 - val_acc: 0.8797\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 1s 75us/step - loss: 0.0211 - acc: 0.9832 - val_loss: 0.0883 - val_acc: 0.8808\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 1s 75us/step - loss: 0.0179 - acc: 0.9876 - val_loss: 0.0917 - val_acc: 0.8734\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 1s 73us/step - loss: 0.0163 - acc: 0.9880 - val_loss: 0.0917 - val_acc: 0.8777\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 1s 73us/step - loss: 0.0143 - acc: 0.9900 - val_loss: 0.0927 - val_acc: 0.8772\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 1s 73us/step - loss: 0.0125 - acc: 0.9922 - val_loss: 0.0945 - val_acc: 0.8749\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 1s 75us/step - loss: 0.0113 - acc: 0.9929 - val_loss: 0.0989 - val_acc: 0.8680\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 1s 72us/step - loss: 0.0098 - acc: 0.9942 - val_loss: 0.0974 - val_acc: 0.8726\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 1s 73us/step - loss: 0.0085 - acc: 0.9952 - val_loss: 0.0991 - val_acc: 0.8709\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 1s 74us/step - loss: 0.0074 - acc: 0.9958 - val_loss: 0.1011 - val_acc: 0.8688\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 1s 75us/step - loss: 0.0068 - acc: 0.9961 - val_loss: 0.1025 - val_acc: 0.8673\n",
            "25000/25000 [==============================] - 2s 65us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.11310992898583412, 0.85376]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYj826Fb4ZM9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "outputId": "932bea71-cafe-4deb-8d4e-0182d4f9abfa"
      },
      "source": [
        "# 1개의 hidden layer 16개 노드, mse\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='tanh',input_shape=(10000,)))\n",
        "# model.add(layers.Dense(16, activation='relu'))\n",
        "# model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))\n",
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 2s 104us/step - loss: 0.4875 - acc: 0.8063 - val_loss: 0.3867 - val_acc: 0.8650\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 1s 77us/step - loss: 0.3126 - acc: 0.9032 - val_loss: 0.3157 - val_acc: 0.8863\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.2406 - acc: 0.9270 - val_loss: 0.2916 - val_acc: 0.8848\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 1s 75us/step - loss: 0.1948 - acc: 0.9411 - val_loss: 0.2838 - val_acc: 0.8848\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.1658 - acc: 0.9512 - val_loss: 0.2765 - val_acc: 0.8867\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.1403 - acc: 0.9593 - val_loss: 0.2767 - val_acc: 0.8900\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.1212 - acc: 0.9653 - val_loss: 0.2910 - val_acc: 0.8830\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.1044 - acc: 0.9710 - val_loss: 0.2985 - val_acc: 0.8834\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 1s 75us/step - loss: 0.0913 - acc: 0.9756 - val_loss: 0.3025 - val_acc: 0.8811\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0783 - acc: 0.9807 - val_loss: 0.3141 - val_acc: 0.8817\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0680 - acc: 0.9841 - val_loss: 0.3400 - val_acc: 0.8776\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 1s 80us/step - loss: 0.0600 - acc: 0.9870 - val_loss: 0.3755 - val_acc: 0.8669\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 1s 78us/step - loss: 0.0498 - acc: 0.9897 - val_loss: 0.3661 - val_acc: 0.8774\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0433 - acc: 0.9914 - val_loss: 0.3840 - val_acc: 0.8736\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 1s 78us/step - loss: 0.0374 - acc: 0.9937 - val_loss: 0.4067 - val_acc: 0.8749\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 1s 77us/step - loss: 0.0318 - acc: 0.9946 - val_loss: 0.4247 - val_acc: 0.8709\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0265 - acc: 0.9956 - val_loss: 0.4709 - val_acc: 0.8629\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0229 - acc: 0.9973 - val_loss: 0.4742 - val_acc: 0.8665\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 1s 76us/step - loss: 0.0187 - acc: 0.9979 - val_loss: 0.4991 - val_acc: 0.8696\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 1s 75us/step - loss: 0.0159 - acc: 0.9985 - val_loss: 0.5186 - val_acc: 0.8650\n",
            "25000/25000 [==============================] - 2s 70us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5737330675029755, 0.85104]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj2LF4VB4qe_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}